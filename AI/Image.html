<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <ul>
        <h1>How to run in a terminal using multiple python files?</font></h1>
        <li>When the code is likely to be long, you may write multiple script files for each content.</li>
        <li>How do we combine multiple python files into one and run them on the terminal?<br>
        The anser is Loading functions defined in B.python into A.python</li>
        <li>from B.py's name import function definited in B.py.</li>
        <li>for example.<br>common.py  def making():</li>
        <li>from common import makeking</li>
        <h1><font color="blue">How to use API?</font></h1>
        <ol>
        <li>You need to send the request to the URL to API.<br>
            By requests.get. (url), specify where to throw the information.<br>
            By the way, to see the contents of response, you can use json method.</li>
        <li>The api docs tell you what to put in your request.<br>
            key id must be required.Therefore, it is necessary to put the key id in params.</li></ol>
        <h1>Scraping</h1>
        <h2>Selenium</h2>
        <li>ブラウザ操作の場合、seleniumパッケージが優れている。</li>
        <li>from selenium import webdriver<br>browser = webdriver.Chrome()<br>ってやったらFileNotFouundErrorが出たから、プロンプト上で<br>
            pip install chromedriver-binary=='自分のクロームのバージョン'を実行してimport chromedriver_binaryで呼び出したらクロームが起動した！！<br>
            from time import sleep #一時停止を行うためのライブラリ。<br>sleep(3)<br>print("hello") #3秒待ったら表示</li>
        <li>idタグをコピーして、要素をID指定で見つけ、場所の情報を取得する。<br><font color="red">browser.find_element_by_id('idタグ名')</font></li>
        <li>send_keys()でキーを送信する</li>
        <li>クラス名で指定して一つだけ要素を取得するには<br>.find_element_by_tag_name('class名')</li>
        <li>クラス名で指定して複数の要素を取得するには<br>.find_elements_by_tag_name('class名')<br>これを実行するとリスト型で返ってくる。</li>
        <h2>Beautiful Soup</h2>
        <li>htmlの構造を解析するライブラリ。</li>
        <li>requestとBeatifulSpup4をインポートする。</li>
        <li>res.textをhtmlで読み込む。<br>soup=BeautifulSoup(res.text, 'html.parser')</li>
        <li>以下、二つの、要素の取得の仕方がある。find_allを使うか、cssセレクタを使うか。</li>
        <li>cssセレクタを使うには<br>.select('.クラス名')　　するとリスト型で返ってくる。一つの要素のみ取得したかったら、select_one</li>
        <li>ヘッドレスモード（GUIではなくCUIで操作するモード）にするには<br></li>      

        <h1>いざ、アプリ制作へ </h1>
        <li>学習済パラメータ<br>学習用データセットを使った学習の結果、得られたパラメータ（係数）のこと。そもそもCNNでは何をやっていたのかというと、<br>
            学習において最も良い精度を誇る最適なパラメータを模索してたからね。</li>
        <li>学習済みモデル<br>学習済みパラメータが組み込まれた推論プログラムのこと。</li>    
        <li>推論プログラム<br>組み込まれた学習済みパラメータを適用することで、入力に対して一定の結果が出力されることを可能にするプログラムのこと。</li>
        <li>画像認識アプリの制作では、重み付きファイルを生成する必要がある！まあ、それが一般に、.h5ファイルね。</li>

        <h1>Abstract concepts</h1>
        <li>Encapsulation<br></li>
        <li>polymorphism<br>In a language corresponding to polymorphism, functions of the same name can be defined repeatedly, 
        and can be summarized as a function without having to prepare separate functions for each type.</li>
        <h1>画像処理</h1>
        <li>画像データを表す画素の濃度値を数値化し、演算処理によって元画像から特徴を抽出する。</li>
        <h1>CNN</h1>
        <li>畳み込み層で学習した位置情報は訓練データに特化（過学習）し、汎化性能が低くなっている可能性がある。<br>
            その場合、プーリング層を用いることで重要な情報のみを残し、汎化性能を向上させることが可能。<br>
            このようにプーリングを施すことで、位置情報の小さな変化に対し頑健なモデルとなる。しかし、例えば９という数字が横に傾いたり、逆さになったり
            といった回転や拡大縮小にまで対応できる訳ではないため、その点は留意しなきゃだね。
        <li>ストライドを大きくとる⇔位置情報を汎化するための対応をとっている</li>    
        <li>畳みこんだ結果を空の配列に格納する。用意した空の入れ物に数字を入れるイメージ。</li>
        <li>Kerasの入力には４次元配列が必要。だからもし、(50,50,3)っていう配列があった時、無理やり(1,50,50,3)に変更する必要がある。<br>
        reason:50*50*3=7500 ⇔ 1*50*50*3<br>例えば、vggモデルにおいて３次元で入力されたときに、Input(shape(50,50,3))で次元を変更する必要がある。</li>
        <h1>im2col</h1>
        <li>畳み込み演算を効率的に扱うためのライブラリ。</li>
        <h1>ミニバッチ学習とk分割交差検証って何がどう違うの？</h1>
        <li></li>
    </ul>
</body>
</html>
